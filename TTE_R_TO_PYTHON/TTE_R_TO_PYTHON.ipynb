{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ecfd4ac-6b14-4b0d-b902-8ac0b559187f",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation (TTE) with Clustering**\n",
    "### CIS 3203N GROUP 3\n",
    "\n",
    "Thesis Partner 1: Dejito, Christine Ann  \n",
    "Thesis Partner 2: Roca, Zophia Maureen  \n",
    "Date: March 9, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions \n",
    "1. Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "2. Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "2. Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "3. Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "4. Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "5. Do this by pair, preferably your thesis partner.\n",
    "6. Push to your github repository.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Target Trial Emulation (TTE)?\n",
    "TTE is a methodological framework in epidemiology that helps reduce biases in observational studies by mimicking the conditions of a randomized controlled trial (RCT).\n",
    "\n",
    "### Why is this important?\n",
    "- Traditional observational studies can have selection bias and confounding factors.\n",
    "- TTE helps analyze causal effects (e.g., \"Does Drug A reduce mortality?\") in a way that is less biased.\n",
    "- It constructs a hypothetical clinical trial using real-world data.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "- **id**:\tUnique patient ID.\n",
    "- **period**:\tTime period (e.g., months or years of follow-up).\n",
    "- treatment\tWhether the patient received treatment (1 = Yes, 0 = No).\n",
    "- **x1, x2, x3, x4**:\tCovariates (predictors, could be patient characteristics).\n",
    "- **age**:\tPatient’s age at the time of observation.\n",
    "- **age_s**:\tStandardized age (scaled between 0 and 1).\n",
    "- **outcome**:\tEvent occurrence (1 = event happened, 0 = censored or no event).\n",
    "- **censored**:\tWhether the data is censored (1 = censored, 0 = not censored).\n",
    "- **eligible**:\tWhether the patient is eligible for the target trial (1 = eligible, 0 = not eligible).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a7807-a2fc-4bd2-b173-d7237a18b0f3",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4309c4e0-9c5d-469c-8e68-480e51163af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError, ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47149f25-b0d2-40df-bb3b-b6d85afc5d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "category must be a Warning subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Suppress specific warnings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwarnings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilterwarnings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPerfectSeparationError\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mConvergenceWarning)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Define a class to encapsulate the trial sequence and associated methods.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\warnings.py:149\u001b[0m, in \u001b[0;36mfilterwarnings\u001b[1;34m(action, message, category, module, lineno, append)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(category, \u001b[38;5;28mtype\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory must be a class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(category, \u001b[38;5;167;01mWarning\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory must be a Warning subclass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lineno, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m lineno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \\\n\u001b[0;32m    152\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineno must be an int >= 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: category must be a Warning subclass"
     ]
    }
   ],
   "source": [
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=PerfectSeparationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Define a class to encapsulate the trial sequence and associated methods.\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.expanded_data = None\n",
    "        self.switch_weight_model = None\n",
    "        self.censor_weight_model = None\n",
    "        self.outcome_model_spec = None\n",
    "        self.outcome_model_result = None\n",
    "\n",
    "    def set_data(self, data, id, period, treatment, outcome, eligible):\n",
    "        \"\"\"Stores the observational data and variable names.\"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.id = id\n",
    "        self.period = period\n",
    "        self.treatment = treatment\n",
    "        self.outcome = outcome\n",
    "        self.eligible = eligible\n",
    "        return self\n",
    "\n",
    "    def set_switch_weight_model(self, numerator_formula, denominator_formula, model_fitter, save_path):\n",
    "        \"\"\"Stores specifications for the treatment switching weight model.\"\"\"\n",
    "        self.switch_weight_model = {\n",
    "            'numerator_formula': numerator_formula,\n",
    "            'denominator_formula': denominator_formula,\n",
    "            'model_fitter': model_fitter,\n",
    "            'save_path': save_path\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def set_censor_weight_model(self, censor_event, numerator_formula, denominator_formula, pool_models, model_fitter, save_path):\n",
    "        \"\"\"Stores specifications for the censoring weight model.\"\"\"\n",
    "        self.censor_weight_model = {\n",
    "            'censor_event': censor_event,\n",
    "            'numerator_formula': numerator_formula,\n",
    "            'denominator_formula': denominator_formula,\n",
    "            'pool_models': pool_models,\n",
    "            'model_fitter': model_fitter,\n",
    "            'save_path': save_path\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Fit logistic regression models and calculate weights.\"\"\"\n",
    "        if self.switch_weight_model:\n",
    "            formula = self.switch_weight_model['denominator_formula']\n",
    "            y, X = patsy.dmatrices(formula, self.data, return_type=\"dataframe\")\n",
    "            model = sm.Logit(y, X).fit()\n",
    "            self.data['weight'] = np.clip(1 / model.predict(X), 0, self.data['weight'].quantile(0.99) if 'weight' in self.data.columns else 1)\n",
    "\n",
    "        if self.censor_weight_model:\n",
    "            formula = self.censor_weight_model['denominator_formula']\n",
    "            y, X = patsy.dmatrices(formula, self.data, return_type=\"dataframe\")\n",
    "            model = sm.Logit(y, X).fit()\n",
    "            self.data['sample_weight'] = 1 / model.predict(X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def set_outcome_model(self, adjustment_terms=None):\n",
    "        \"\"\"\n",
    "        Specify the outcome model. In the R code the formula included\n",
    "        assigned_treatment, x2, followup_time (and its square), trial_period (and its square).\n",
    "        Here we hard‐code a similar formula using patsy syntax.\n",
    "        \"\"\"\n",
    "        self.outcome_model_spec = {\n",
    "            'formula': \"outcome ~ assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\",\n",
    "            'adjustment_terms': adjustment_terms\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def set_expansion_options(self, output, chunk_size):\n",
    "        \"\"\"\n",
    "        Set options for expanding the trial data.\n",
    "        For example, 'chunk_size' determines how many patients are processed at a time.\n",
    "        \"\"\"\n",
    "        self.expansion_options = {\n",
    "            'output': output,\n",
    "            'chunk_size': chunk_size\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def expand_trials(self):\n",
    "        \"\"\"\n",
    "        Expand the observational dataset into a sequence of trials.\n",
    "        (This is a simplified placeholder. In a real scenario, you might need to create\n",
    "         multiple rows per patient with varying trial periods and follow‐up times.)\n",
    "        \"\"\"\n",
    "        df = self.data.copy()\n",
    "        # Add dummy trial-specific columns:\n",
    "        df['trial_period'] = 0  # In practice, this would vary by trial\n",
    "        df['followup_time'] = df[self.period]  # For example, using the period as follow-up time\n",
    "        df['assigned_treatment'] = df[self.treatment]  # You might compute this differently\n",
    "        self.expanded_data = df\n",
    "        return self\n",
    "\n",
    "    def load_expanded_data(self, seed=None, p_control=1.0):\n",
    "        \"\"\"\n",
    "        For large datasets, sample control observations.\n",
    "        p_control: probability to include an observation with outcome == 0.\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        df = self.expanded_data.copy()\n",
    "        control_mask = df[self.outcome] == 0\n",
    "        sample_mask = (~control_mask) | (np.random.rand(len(df)) < p_control)\n",
    "        self.expanded_data = df[sample_mask].reset_index(drop=True)\n",
    "        return self\n",
    "\n",
    "    def fit_msm(self, weight_cols, modify_weights=None):\n",
    "        \"\"\"\n",
    "        Fit the Marginal Structural Model (MSM) using a GLM (logistic regression).\n",
    "        weight_cols: list of columns that contain weights.\n",
    "        modify_weights: function to winsorize or otherwise modify the weights.\n",
    "        \"\"\"\n",
    "        formula = self.outcome_model_spec['formula']\n",
    "        df = self.expanded_data.copy()\n",
    "        # Modify weights if necessary:\n",
    "        for col in weight_cols:\n",
    "            if col in df.columns:\n",
    "                if modify_weights is not None:\n",
    "                    df[col] = modify_weights(df[col])\n",
    "            else:\n",
    "                df[col] = 1.0\n",
    "        # Combine the weights (here, multiply them together)\n",
    "        df['combined_weight'] = df[weight_cols].prod(axis=1)\n",
    "        # Create design matrices using patsy:\n",
    "        y, X = patsy.dmatrices(formula, df, return_type='dataframe')\n",
    "        # Fit a logistic regression model (GLM with binomial family)\n",
    "        model = sm.GLM(y, X, family=sm.families.Binomial(), var_weights=df['combined_weight'])\n",
    "        result = model.fit()\n",
    "        self.outcome_model_result = result\n",
    "        return self\n",
    "\n",
    "    def predict_msm(self, newdata, predict_times, type=\"survival\"):\n",
    "        \"\"\"\n",
    "        Generate predictions from the outcome model.\n",
    "        For demonstration we use a dummy transformation of predicted probabilities.\n",
    "        \"\"\"\n",
    "        formula = self.outcome_model_spec['formula']\n",
    "        _, X_new = patsy.dmatrices(formula, newdata, return_type='dataframe')\n",
    "        preds = self.outcome_model_result.predict(X_new)\n",
    "        # Here we mimic survival predictions (e.g., 1 - risk) and assume a linear decay over time.\n",
    "        results = []\n",
    "        for t in predict_times:\n",
    "            # Ensure survival probability starts at 1 and decreases over time\n",
    "            surv_prob = 1 - preds * (t / max(predict_times))\n",
    "            surv_prob = np.clip(surv_prob, 0, 1)  # Ensure probabilities are between 0 and 1\n",
    "            results.append(surv_prob)\n",
    "        survival_df = pd.DataFrame({t: results[i] for i, t in enumerate(predict_times)})\n",
    "        # Optionally include follow-up time from newdata:\n",
    "        if 'followup_time' in newdata.columns:\n",
    "            survival_df['followup_time'] = newdata['followup_time'].values\n",
    "        return survival_df\n",
    "\n",
    "# =================== Main Workflow ===================\n",
    "\n",
    "# 1. Setup\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# 2. Data Preparation\n",
    "# Load the dataset from the CSV file\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(data_censored.head())\n",
    "trial_pp.set_data(data=data_censored, id=\"id\", period=\"period\", treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "trial_itt.set_data(data=data_censored, id=\"id\", period=\"period\", treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "\n",
    "# 3. Weight Models and Censoring\n",
    "# (Set up the models as in the R code.)\n",
    "trial_pp.set_switch_weight_model(\n",
    "    numerator_formula=\"treatment ~ age\",\n",
    "    denominator_formula=\"treatment ~ age + x1 + x3\",\n",
    "    model_fitter=\"logit\",  # here we indicate that we will use a logistic model (statsmodels)\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator_formula=\"1 - censored ~ x2\",\n",
    "    denominator_formula=\"1 - censored ~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=\"logit\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator_formula=\"1 - censored ~ x2\",\n",
    "    denominator_formula=\"1 - censored ~ x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    model_fitter=\"logit\",\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "# 4. Calculate Weights\n",
    "trial_pp.calculate_weights()\n",
    "trial_itt.calculate_weights()\n",
    "\n",
    "# 5. Specify Outcome Model\n",
    "trial_pp.set_outcome_model()\n",
    "trial_itt.set_outcome_model(adjustment_terms=\"x2\")\n",
    "\n",
    "# 6. Expand Trials\n",
    "trial_pp.set_expansion_options(output=\"pandas\", chunk_size=500)\n",
    "trial_itt.set_expansion_options(output=\"pandas\", chunk_size=500)\n",
    "trial_pp.expand_trials()\n",
    "trial_itt.expand_trials()\n",
    "\n",
    "# 7. Load or Sample from Expanded Data\n",
    "trial_itt.load_expanded_data(seed=1234, p_control=0.5)\n",
    "\n",
    "# 8. Fit Marginal Structural Model\n",
    "# Here we use a lambda function to winsorize (clip) extreme weights at the 99th percentile.\n",
    "trial_itt.fit_msm(\n",
    "    weight_cols=[\"weight\", \"sample_weight\"],\n",
    "    modify_weights=lambda w: w.clip(upper=w.quantile(0.99))\n",
    ")\n",
    "\n",
    "# Print model summary (similar to show_weight_models() in R)\n",
    "print(trial_itt.outcome_model_result.summary())\n",
    "\n",
    "# 9. Inference\n",
    "# For prediction, we filter the expanded data to include only a subset (e.g., trial_period == 0).\n",
    "newdata = trial_itt.expanded_data[trial_itt.expanded_data['trial_period'] == 0]\n",
    "predict_times = list(range(11))  # follow-up times 0 to 10\n",
    "preds = trial_itt.predict_msm(newdata=newdata, predict_times=predict_times, type=\"survival\")\n",
    "\n",
    "# Compute mean survival probability across observations for each time point\n",
    "mean_survival = preds.drop(columns=['followup_time'], errors='ignore').mean(axis=0)\n",
    "\n",
    "# Compute confidence intervals (assuming normal approximation for demonstration)\n",
    "std_survival = preds.drop(columns=['followup_time'], errors='ignore').std(axis=0)\n",
    "ci_upper = mean_survival + 1.96 * std_survival / np.sqrt(len(preds))\n",
    "ci_lower = mean_survival - 1.96 * std_survival / np.sqrt(len(preds))\n",
    "\n",
    "# Plot survival difference with confidence intervals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(predict_times, mean_survival, 'k', label=\"Survival difference\")  # Black solid line\n",
    "plt.plot(predict_times, ci_upper, 'r--')  # Red dashed upper confidence interval\n",
    "plt.plot(predict_times, ci_lower, 'r--')  # Red dashed lower confidence interval\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Follow up time\")\n",
    "plt.ylabel(\"Survival difference\")\n",
    "plt.legend()\n",
    "plt.title(\"Survival Differences Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b8ced-fa63-4e96-9eab-7fed52d8fd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
